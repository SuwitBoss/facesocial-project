# ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Deepfake Detection Model

## üìã ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ

**‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•:** Deepfake-Detection-Exp-02-21-ONNX  
**‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô:** v1.0  
**‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó:** Image Classification (Binary Classification)  
**‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ:** Vision Transformer (ViT) based on Google's vit-base-patch16-224-in21k  
**‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥:** 98.84%  

## üéØ ‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó

```
Class Mapping:
‚îú‚îÄ‚îÄ 0: "Deepfake" (‡∏†‡∏≤‡∏û‡∏õ‡∏•‡∏≠‡∏°/‡∏™‡∏±‡∏á‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå)
‚îî‚îÄ‚îÄ 1: "Real" (‡∏†‡∏≤‡∏û‡∏à‡∏£‡∏¥‡∏á)

Label Mapping:
‚îú‚îÄ‚îÄ "Deepfake": 0
‚îî‚îÄ‚îÄ "Real": 1
```

## üìä ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÇ‡∏°‡πÄ‡∏î‡∏•

| Class | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| Deepfake | 99.62% | 98.06% | 98.83% | 1,600 |
| Real | 98.09% | 99.62% | 98.85% | 1,600 |
| **Overall** | **98.86%** | **98.84%** | **98.84%** | **3,200** |

## üóÇÔ∏è ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏´‡πâ

| ‡πÑ‡∏ü‡∏•‡πå | ‡∏Ç‡∏ô‡∏≤‡∏î | ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß | ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ | ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö |
|------|------|-----------|------------|-------------|
| `model.onnx` | ‡πÉ‡∏´‡∏ç‡πà‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î | ‡∏ä‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î | ‡∏™‡∏π‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î | ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á |
| `model_fp16.onnx` | ‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á | ‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á | ‡∏™‡∏π‡∏á | **‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ** |
| `model_int8.onnx` | ‡πÄ‡∏•‡πá‡∏Å | ‡πÄ‡∏£‡πá‡∏ß | ‡∏î‡∏µ | CPU inference |
| `model_uint8.onnx` | ‡πÄ‡∏•‡πá‡∏Å | ‡πÄ‡∏£‡πá‡∏ß | ‡∏î‡∏µ | Mobile/Embedded devices |
| `model_q4.onnx` | ‡πÄ‡∏•‡πá‡∏Å‡∏°‡∏≤‡∏Å | ‡πÄ‡∏£‡πá‡∏ß‡∏°‡∏≤‡∏Å | ‡∏û‡∏≠‡πÉ‡∏ä‡πâ | Real-time applications |
| `model_q4f16.onnx` | ‡πÄ‡∏•‡πá‡∏Å‡∏°‡∏≤‡∏Å | ‡πÄ‡∏£‡πá‡∏ß‡∏°‡∏≤‡∏Å | ‡∏û‡∏≠‡πÉ‡∏ä‡πâ | Hybrid precision |
| `model_bnb4.onnx` | ‡πÄ‡∏•‡πá‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î | ‡πÄ‡∏£‡πá‡∏ß‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î | ‡∏ï‡πà‡∏≥‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î | Resource-constrained |

## ‚öôÔ∏è ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏• (Model Configuration)

### ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏´‡∏•‡∏±‡∏Å
```json
{
  "model_type": "vit",
  "architectures": ["ViTForImageClassification"],
  "hidden_size": 768,
  "num_hidden_layers": 12,
  "num_attention_heads": 12,
  "intermediate_size": 3072,
  "patch_size": 16,
  "image_size": 224,
  "num_channels": 3,
  "problem_type": "single_label_classification"
}
```

### ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏û
```json
{
  "do_resize": true,
  "do_rescale": true,
  "do_normalize": true,
  "size": {"height": 224, "width": 224},
  "rescale_factor": 0.00392156862745098,
  "image_mean": [0.5, 0.5, 0.5],
  "image_std": [0.5, 0.5, 0.5],
  "resample": 2
}
```

### ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå Quantization
```json
{
  "modes": ["fp16", "q8", "int8", "uint8", "q4", "q4f16", "bnb4"],
  "per_channel": true,
  "reduce_range": true,
  "is_symmetric": true,
  "quant_type": 1
}
```

## üöÄ ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

### 1. ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Dependencies

```bash
pip install transformers torch pillow onnxruntime
# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö GPU (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
pip install onnxruntime-gpu
```

### 2. ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ú‡πà‡∏≤‡∏ô Hugging Face Pipeline

```python
from transformers import pipeline
from PIL import Image

# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
pipe = pipeline(
    'image-classification', 
    model="prithivMLmods/Deepfake-Detection-Exp-02-21",
    device=0  # ‡πÉ‡∏ä‡πâ GPU, ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô -1 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö CPU
)

# ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•
image_path = "path_to_your_image.jpg"
result = pipe(image_path)
print(f"Result: {result}")

# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
# [{'label': 'Real', 'score': 0.9876}, {'label': 'Deepfake', 'score': 0.0124}]
```

### 3. ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ú‡πà‡∏≤‡∏ô PyTorch

```python
from transformers import ViTForImageClassification, ViTImageProcessor
from PIL import Image
import torch

# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞ processor
model = ViTForImageClassification.from_pretrained(
    "prithivMLmods/Deepfake-Detection-Exp-02-21"
)
processor = ViTImageProcessor.from_pretrained(
    "prithivMLmods/Deepfake-Detection-Exp-02-21"
)

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏õ‡πá‡∏ô evaluation mode
model.eval()

# ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏û
def predict_image(image_path):
    image = Image.open(image_path).convert("RGB")
    inputs = processor(images=image, return_tensors="pt")
    
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        probabilities = torch.nn.functional.softmax(logits, dim=-1)
        predicted_class = torch.argmax(logits, dim=1).item()
    
    # ‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    label = model.config.id2label[predicted_class]
    confidence = probabilities[0][predicted_class].item()
    
    return {
        "label": label,
        "confidence": confidence,
        "probabilities": {
            "Deepfake": probabilities[0][0].item(),
            "Real": probabilities[0][1].item()
        }
    }

# ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
result = predict_image("your_image.jpg")
print(f"Prediction: {result['label']}")
print(f"Confidence: {result['confidence']:.4f}")
print(f"Probabilities: {result['probabilities']}")
```

### 4. ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ú‡πà‡∏≤‡∏ô ONNX Runtime

```python
import onnxruntime as ort
import numpy as np
from PIL import Image

# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• ONNX
session = ort.InferenceSession("model_fp16.onnx")

def preprocess_image(image_path):
    image = Image.open(image_path).convert("RGB")
    image = image.resize((224, 224))
    
    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô numpy array ‡πÅ‡∏•‡∏∞ normalize
    image_array = np.array(image).astype(np.float32) / 255.0
    image_array = (image_array - 0.5) / 0.5  # Normalize [-1, 1]
    
    # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô shape ‡πÄ‡∏õ‡πá‡∏ô (1, 3, 224, 224)
    image_array = np.transpose(image_array, (2, 0, 1))
    image_array = np.expand_dims(image_array, axis=0)
    
    return image_array

def predict_onnx(image_path):
    input_data = preprocess_image(image_path)
    
    # ‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
    outputs = session.run(None, {"pixel_values": input_data})
    logits = outputs[0]
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì probabilities
    probabilities = np.exp(logits) / np.sum(np.exp(logits), axis=1, keepdims=True)
    predicted_class = np.argmax(probabilities, axis=1)[0]
    
    labels = {0: "Deepfake", 1: "Real"}
    
    return {
        "label": labels[predicted_class],
        "confidence": probabilities[0][predicted_class],
        "probabilities": {
            "Deepfake": probabilities[0][0],
            "Real": probabilities[0][1]
        }
    }

# ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
result = predict_onnx("your_image.jpg")
print(result)
```

## üìù ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

### ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û

```python
# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Mixed Precision (‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥)
with torch.cuda.amp.autocast():
    outputs = model(**inputs)

# Batch Processing (‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô)
images = [Image.open(path) for path in image_paths]
inputs = processor(images=images, return_tensors="pt")
```

### Threshold Setting

```python
def classify_with_threshold(probabilities, threshold=0.5):
    """
    ‡∏Å‡∏≥‡∏´‡∏ô‡∏î threshold ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å
    - threshold ‡∏™‡∏π‡∏á: ‡∏•‡∏î False Positive (‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô)
    - threshold ‡∏ï‡πà‡∏≥: ‡∏•‡∏î False Negative (‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô)
    """
    deepfake_prob = probabilities["Deepfake"]
    
    if deepfake_prob > threshold:
        return "Deepfake", deepfake_prob
    else:
        return "Real", probabilities["Real"]

# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
result = predict_image("image.jpg")
classification, confidence = classify_with_threshold(
    result["probabilities"], 
    threshold=0.7  # ‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
)
```

## ‚ö†Ô∏è ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏£‡∏∞‡∏ß‡∏±‡∏á

### 1. ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ
- **‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û:** ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏ó‡∏µ‡πà 224x224 pixels
- **‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏†‡∏≤‡∏û:** ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö RGB ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
- **‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÑ‡∏ü‡∏•‡πå:** JPG, PNG, BMP

### 2. ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
- ‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ deepfake ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡πÄ‡∏´‡πá‡∏ô
- ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏à‡∏•‡∏î‡∏•‡∏á‡∏Å‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏π‡∏á
- ‡∏≠‡∏≤‡∏à‡∏°‡∏µ bias ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ù‡∏∂‡∏Å

### 3. ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á
```python
# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏†‡∏≤‡∏û‡∏Å‡πà‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
def validate_image(image_path):
    try:
        image = Image.open(image_path)
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û
        if min(image.size) < 224:
            print(f"Warning: Image resolution is low ({image.size})")
        
        return True, image
    except Exception as e:
        print(f"Error loading image: {e}")
        return False, None

# ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
def safe_predict(image_path, confidence_threshold=0.8):
    is_valid, image = validate_image(image_path)
    if not is_valid:
        return None
    
    result = predict_image(image_path)
    
    if result["confidence"] < confidence_threshold:
        return {
            "prediction": "Uncertain",
            "confidence": result["confidence"],
            "recommendation": "Manual review required"
        }
    
    return result
```

## üîß ‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ Memory ‡∏´‡∏°‡∏î
```python
# ‡∏•‡∏î batch size
inputs = processor(images=image, return_tensors="pt", max_length=1)

# ‡πÉ‡∏ä‡πâ gradient checkpointing
model.gradient_checkpointing_enable()

# Clear cache
torch.cuda.empty_cache()
```

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß
```python
# ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• quantized
model_path = "model_int8.onnx"  # ‡∏´‡∏£‡∏∑‡∏≠ model_q4.onnx

# ‡∏õ‡∏¥‡∏î gradient computation
with torch.no_grad():
    outputs = model(**inputs)
```

## üìû ‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏±‡∏ö‡∏™‡∏ô‡∏∏‡∏ô‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°

- **Repository:** `prithivMLmods/Deepfake-Detection-Exp-02-21`
- **License:** Apache 2.0
- **Dataset:** `prithivMLmods/Deepfake-vs-Real`
- **Base Model:** `google/vit-base-patch16-224-in21k`

---

**‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏:** ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ô‡∏µ‡πâ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 28 ‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏° 2025 ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö repository ‡∏´‡∏•‡∏±‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î